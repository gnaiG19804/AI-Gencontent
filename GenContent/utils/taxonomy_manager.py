import requests
import json
import sys
import os
from pathlib import Path
from typing import List, Optional
import hashlib

# Fix import path ƒë·ªÉ c√≥ th·ªÉ ch·∫°y t·ª´ b·∫•t k·ª≥ ƒë√¢u
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.messages import HumanMessage, SystemMessage
from config.config import Config
from llms.llm import llm_taxonomy

# File cache path
CACHE_FILE = Path(__file__).parent.parent / "cached_categories.json"


def get_store_description_hash(store_description: str) -> str:
    """
    T·∫°o hash t·ª´ store description ƒë·ªÉ so s√°nh
    """
    return hashlib.md5(store_description.encode()).hexdigest()


def load_cached_categories() -> Optional[List[str]]:
    """
    Load categories t·ª´ file cache n·∫øu STORE_DESCRIPTION kh√¥ng ƒë·ªïi
    """
    if not CACHE_FILE.exists():
        print("üìÇ Ch∆∞a c√≥ file cache categories")
        return None
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        
        current_hash = get_store_description_hash(Config.STORE_DESCRIPTION or "")
        cached_hash = cache_data.get("store_description_hash")
        
        if current_hash == cached_hash:
            categories = cache_data.get("categories", [])
            print(f"‚úÖ Load {len(categories)} categories t·ª´ cache (STORE_DESCRIPTION kh√¥ng ƒë·ªïi)")
            return categories
        else:
            print("‚ö†Ô∏è  STORE_DESCRIPTION ƒë√£ thay ƒë·ªïi, c·∫ßn refresh categories")
            return None
            
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc cache: {e}")
        return None


def save_categories_to_cache(categories: List[str]):
    """
    L∆∞u categories v√†o file cache k√®m hash c·ªßa STORE_DESCRIPTION
    """
    try:
        cache_data = {
            "store_description": Config.STORE_DESCRIPTION,
            "store_description_hash": get_store_description_hash(Config.STORE_DESCRIPTION or ""),
            "categories": categories,
            "timestamp": str(Path(__file__).stat().st_mtime)
        }
        
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ ƒê√£ l∆∞u {len(categories)} categories v√†o cache file: {CACHE_FILE.name}")
        
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u cache: {e}")


def get_filtering_keywords(llm, store_description):
    """
    D√πng LLM ƒë·ªÉ ph√¢n t√≠ch m√¥ t·∫£ c·ª≠a h√†ng v√† ƒë∆∞a ra c√°c t·ª´ kh√≥a ti·∫øng Anh
    ƒë·ªÉ l·ªçc danh m·ª•c Shopify.
    """
    print(f"ü§ñ AI ƒëang suy nghƒ© t·ª´ kh√≥a cho: '{store_description}'...")
    
    prompt = Config.SYSTEM_PROMPT_TAXONOMY.format(store_description=store_description)
    
    try:
        messages = [HumanMessage(content=prompt)]
        response = llm.invoke(messages)
        content = response.content.strip()
        
        start = content.find('[')
        end = content.rfind(']') + 1
        if start != -1 and end > start:
            keywords = json.loads(content[start:end])
            print(f"‚úÖ AI ƒë·ªÅ xu·∫•t t·ª´ kh√≥a l·ªçc: {keywords}")
            return keywords
        else:
            print("‚ö†Ô∏è  LLM kh√¥ng tr·∫£ v·ªÅ JSON ƒë√∫ng format, d√πng keywords m·∫∑c ƒë·ªãnh")
            return ["Apparel", "Clothing", "Fashion"] 
            
    except Exception as e:
        print(f"‚ùå L·ªói AI sinh t·ª´ kh√≥a: {e}")
        return ["Apparel", "Clothing", "Fashion"]


def build_niche_taxonomy(keywords):
    """
    T·∫£i Shopify taxonomy v√† l·ªçc theo keywords
    """
    # Shopify taxonomy s·ª≠ d·ª•ng versioned releases (2024-10, 2024-07...)
    # URL m·ªõi: trong th∆∞ m·ª•c dist/
    url = "https://raw.githubusercontent.com/Shopify/product-taxonomy/main/dist/en/categories.json"
    
    print("üì• ƒêang t·∫£i v√† l·ªçc danh m·ª•c Shopify...")
    try:
        response = requests.get(url)
        response.raise_for_status()
        
        # Parse JSON
        text = response.text.strip()
        data = json.loads(text)
        
        # Shopify taxonomy format: {version, verticals: [{categories: [...]}]}
        if "verticals" not in data:
            print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y 'verticals' key. Keys: {list(data.keys())}")
            return []
        
        # Danh s√°ch verticals c·∫ßn b·ªè qua (kh√¥ng li√™n quan ƒë·∫øn clothing/fashion)
        exclude_verticals = [
            "Animals & Pet Supplies",
            "Business & Industrial", 
            "Hardware",
            "Vehicles & Parts",
            "Mature"
        ]
        
        # Extract all categories from relevant verticals only
        all_categories = []
        for vertical in data["verticals"]:
            vertical_name = vertical.get("name", "Unknown")
            
            # Skip excluded verticals
            if vertical_name in exclude_verticals:
                continue
                
            categories_in_vertical = vertical.get("categories", [])
            all_categories.extend(categories_in_vertical)
        
        print(f"T√¨m th·∫•y {len(all_categories)} categories t·ª´ {len(data['verticals']) - len([v for v in data['verticals'] if v.get('name') in exclude_verticals])} verticals (ƒë√£ lo·∫°i b·ªè {len([v for v in data['verticals'] if v.get('name') in exclude_verticals])} verticals kh√¥ng li√™n quan)")
        
        # Filter by keywords v·ªõi scoring ƒë·ªÉ l·∫•y top categories
        category_scores = []  # List of (name, id, score, matched_keywords)
        
        for cat in all_categories:
            name = cat.get("name", "")
            cat_id = cat.get("id", "")  # Extract category ID
            if not name:
                continue
            
            # T√≠nh ƒëi·ªÉm relevance
            score = 0
            matched_keywords = []
            
            for keyword in keywords:
                if len(keyword) < 10:
                    # Exact word match cho keyword ng·∫Øn
                    if keyword.lower() in name.lower().split():
                        score += 2  # ƒêi·ªÉm cao h∆°n cho exact match
                        matched_keywords.append(keyword)
                else:
                    # Substring match cho keyword d√†i
                    if keyword.lower() in name.lower():
                        score += 1
                        matched_keywords.append(keyword)
            
            # Bonus ƒëi·ªÉm n·∫øu match nhi·ªÅu keywords
            if len(matched_keywords) > 1:
                score += len(matched_keywords)
            
            # ∆Øu ti√™n categories ng·∫Øn g·ªçn (th∆∞·ªùng l√† parent categories)
            if score > 0 and len(name.split()) <= 3:
                score += 0.5
            
            if score > 0:
                category_scores.append({
                    "name": name,
                    "id": cat_id,
                    "score": score,
                    "matched_keywords": matched_keywords
                })
        
        # Sort theo score gi·∫£m d·∫ßn v√† l·∫•y top 25
        category_scores.sort(key=lambda x: x["score"], reverse=True)
        top_categories = category_scores[:25]  # Ch·ªâ l·∫•y top 25 categories
        
        # Return list of dicts with name and id
        filtered_list = [{"name": cat["name"], "id": cat["id"]} for cat in top_categories]
        
        print(f"‚úÖ ƒê√£ l·ªçc xong! T·ª´ {len(all_categories)} danh m·ª•c -> C√≤n {len(category_scores)} danh m·ª•c match -> L·∫•y top {len(filtered_list)} danh m·ª•c ph√π h·ª£p nh·∫•t.")
        
        # Debug: Show top 5 v·ªõi scores
        if top_categories:
            print("\nüèÜ Top 5 categories (v·ªõi ƒëi·ªÉm):")
            for i, cat in enumerate(top_categories[:5], 1):
                print(f"  {i}. {cat['name']} (ID: {cat['id']}, score: {cat['score']}, matched: {', '.join(cat['matched_keywords'])})")
        
        return filtered_list
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå L·ªói t·∫£i t·ª´ GitHub: {e}")
        return []
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói parse JSON: {e}")
        print(f"Response preview: {response.text[:200]}...")
        return []
    except Exception as e:
        print(f"‚ùå L·ªói t·∫£i taxonomy: {e}")
        import traceback
        traceback.print_exc()
        return []


def get_or_refresh_categories() -> List[str]:
    """
    Main function: Load t·ª´ cache ho·∫∑c refresh n·∫øu c·∫ßn
    """
    # B∆∞·ªõc 1: Th·ª≠ load t·ª´ cache
    cached = load_cached_categories()
    if cached:
        return cached
    
    # B∆∞·ªõc 2: Cache miss ho·∫∑c STORE_DESCRIPTION ƒë·ªïi -> Refresh
    print("\nüîÑ Refreshing categories t·ª´ Shopify taxonomy...")
    
    if not Config.STORE_DESCRIPTION:
        print("‚ö†Ô∏è  Ch∆∞a c√≥ STORE_DESCRIPTION, d√πng default")
        default_categories = ["Apparel & Accessories", "Clothing", "Clothing Tops"]
        save_categories_to_cache(default_categories)
        return default_categories
    
    # LLM ph√¢n t√≠ch ‚Üí keywords
    keywords = get_filtering_keywords(llm_taxonomy, Config.STORE_DESCRIPTION)
    
    # Filter taxonomy
    categories = build_niche_taxonomy(keywords)
    
    if not categories:
        print("‚ö†Ô∏è  Kh√¥ng l·∫•y ƒë∆∞·ª£c categories, d√πng default")
        categories = ["Apparel & Accessories", "Clothing"]
    
    # L∆∞u v√†o cache
    save_categories_to_cache(categories)
    
    return categories


if __name__ == "__main__":
    # Test script
    print("=" * 60)
    print("TAXONOMY MANAGER - FILE CACHE TEST")
    print("=" * 60)
    
    categories = get_or_refresh_categories()
    
    print(f"\nüì¶ K·∫øt qu·∫£: {len(categories)} categories")
    print("\nTop 10:")
    for i, cat in enumerate(categories[:10], 1):
        print(f"  {i}. {cat}")
    
    print(f"\nüíæ Cache file location: {CACHE_FILE}")